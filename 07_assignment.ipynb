{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WiktoriaGnojek23/DATA-602/blob/main/07_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2QZetSDszc"
      },
      "source": [
        "# **Assignment 7**\n",
        "\n",
        "# **Weeks 8 & 9 - Pandas**\n",
        "* In this homework assignment, you will explore and analyze a public dataset of your choosing. Since this assignment is “open-ended” in nature, you are free to expand upon the requirements below. However, you must meet the minimum requirments as indicated in each section. \n",
        "\n",
        "* You must use Pandas as the **primary tool** to process your data.\n",
        "\n",
        "* The preferred method for this analysis is in a .ipynb file. Feel free to use whichever platform of your choosing.  \n",
        " * https://www.youtube.com/watch?v=inN8seMm7UI (Getting started with Colab).\n",
        "\n",
        "* Your data should need some \"work\", or be considered \"dirty\".  You must show your skills in data cleaning/wrangling.\n",
        "\n",
        "### **Some data examples:**\n",
        "•\thttps://www.data.gov/\n",
        "\n",
        "•\thttps://opendata.cityofnewyork.us/\n",
        "\n",
        "•\thttps://datasetsearch.research.google.com/\n",
        "\n",
        "•\thttps://archive.ics.uci.edu/ml/index.php\n",
        "\n",
        "### **Resources:**\n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html \n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
        "\n",
        "\n",
        "### **Headings or comments**\n",
        "**You are required to make use of comments, or headings for each section.  You must explain what your code is doing, and the results of running your code.**  Act as if you were giving this assignment to your manager - you must include clear and descriptive information for each section.\n",
        "\n",
        "### **You may work as a group or indivdually on this assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW3w6p8rqgxu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this section, please describe the dataset you are using.  Include a link to the source of this data.  You should also provide some explanation on why you choose this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PnfMOFzOXz"
      },
      "source": [
        "Students Performance in Exams\n",
        "Marks secured by the students in various subjects. \n",
        "To understand the influence of the parents background, test preparation etc on students performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bp8cdDxDs2t"
      },
      "source": [
        "______________\n",
        "# Data Exploration\n",
        "Import your dataset into your .ipynb, create dataframes, and explore your data.  \n",
        "\n",
        "Include: \n",
        "\n",
        "* Summary statistics means, medians, quartiles, \n",
        "* Missing value information\n",
        "* Any other relevant information about the dataset.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJmbafkEhhq"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"https://raw.githubusercontent.com/WiktoriaGnojek23/DATA-602/main/StudentsPerformance.csv\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.head(10))\n",
        "\n",
        "# relevant information\n",
        "print(\"Number of rows:\", len(df))\n",
        "print(\"Number of columns:\", len(df.columns))\n",
        "\n",
        "# Calculate summary statistics\n",
        "summary_stats = df.describe()\n",
        "\n",
        "# specific statistics\n",
        "means = summary_stats.loc['mean']\n",
        "medians = summary_stats.loc['50%']  # equivalent to summary_stats.loc['median']\n",
        "quartiles = summary_stats.loc[['25%', '50%', '75%']]\n",
        "\n",
        "# Print the results\n",
        "print(\"Means:\")\n",
        "print(means)\n",
        "print(\"\\nMedians:\")\n",
        "print(medians)\n",
        "print(\"\\nQuartiles:\")\n",
        "print(quartiles)\n",
        "\n",
        "# missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Print the missing value information\n",
        "print(\"Missing Value Information:\")\n",
        "print(missing_values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSLIafaEGVK"
      },
      "source": [
        "# Data Wrangling\n",
        "Create a subset of your original data and perform the following.  \n",
        "\n",
        "1. Modify multiple column names.\n",
        "\n",
        "2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\n",
        "\n",
        "3. Fix missing and invalid values in data.\n",
        "\n",
        "4. Create new columns based on existing columns or calculations.\n",
        "\n",
        "5. Drop column(s) from your dataset.\n",
        "\n",
        "6. Drop a row(s) from your dataset.\n",
        "\n",
        "7. Sort your data based on multiple variables. \n",
        "\n",
        "8. Filter your data based on some condition. \n",
        "\n",
        "9. Convert all the string values to upper or lower cases in one column.\n",
        "\n",
        "10. Check whether numeric values are present in a given column of your dataframe.\n",
        "\n",
        "11. Group your dataset by one column, and get the mean, min, and max values by group. \n",
        "  * Groupby()\n",
        "  * agg() or .apply()\n",
        "\n",
        "12. Group your dataset by two columns and then sort the aggregated results within the groups. \n",
        "\n",
        "**You are free (and should) to add on to these questions.  Please clearly indicate in your assignment your answers to these questions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VWWvvynEiQT"
      },
      "source": [
        "from pandas.core.indexers.objects import calculate_variable_window_bounds\n",
        "## Modify multiple column names\n",
        "df = df.rename(columns={'gender': 'Gender', 'lunch':'Lunch'})\n",
        "\n",
        "## Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\n",
        "## check types - none needed all labeled correctly\n",
        "print(df.dtypes)\n",
        "## Fix missing and invalid values in data.\n",
        "## No missing values\n",
        "print(df.isnull().sum())\n",
        "## Create a new column\n",
        "df['total_score'] = df['math score'] + df['reading score'] + df['writing score']\n",
        "df['pass_status'] = df['total_score'].apply(lambda x: 'Pass' if x >= 150 else 'Fail')\n",
        "##Drop column(s) from your dataset.\n",
        "df = df.drop('parental level of education', axis=1)\n",
        "##Drop a row(s) from your dataset.\n",
        "df = df.drop([1,7])\n",
        "##Sort your data based on multiple variables.\n",
        "sorted_df = df.sort_values(by=['test preparation course', 'reading score'], ascending=[True, False])\n",
        "##Filter your data based on some condition.\n",
        "filtered_df = df[df['Gender'] == 'male']\n",
        "##Convert all the string values to upper or lower cases in one column.\n",
        "df['Gender'] = df['Gender'].str.upper()\n",
        "# numeric values\n",
        "name_score = 'writing score'\n",
        "numeric_true = pd.to_numeric(df[name_score], errors='coerce').notnull().all()\n",
        "# Print the result\n",
        "if numeric_true:\n",
        "    print(f\"Column '{name_score}' contains numeric values.\")\n",
        "else:\n",
        "    print(f\"Column '{name_score}' contains non-numeric values.\")\n",
        "##Group your dataset by one column, and get the mean, min, and max values by group.\n",
        "calculates = df.groupby('Gender').agg({'writing score': ['mean', 'min', 'max']})\n",
        "##Group your dataset by two columns and then sort the aggregated results within the groups.\n",
        "calc_2 = df.groupby(['Gender', 'race/ethnicity']).agg({'writing score': 'mean'}).sort_values(by='writing score')\n",
        "print(df.head())\n",
        "print(calculates)\n",
        "print(calc_2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions  \n",
        "\n",
        "After exploring your dataset, provide a short summary of what you noticed from this dataset.  What would you explore further with more time?"
      ],
      "metadata": {
        "id": "tujjevRpXEen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was a very interesting dataset to work with. Some things noticed include that females have a larger writing score mean then males, but males have a larger min. We can also note that writing score increased as the group letter increases. "
      ],
      "metadata": {
        "id": "eLOABu5wcwWg"
      }
    }
  ]
}